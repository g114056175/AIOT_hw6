import streamlit as st
import pandas as pd
import sqlite3
import os
import subprocess
import sys
import matplotlib.pyplot as plt
import matplotlib
import requests
from bs4 import BeautifulSoup
import time

# --- å…¨åŸŸå¸¸æ•¸è¨­å®š ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_FILE = os.path.join(BASE_DIR, 'data.db')
CRAWLER_SCRIPT = 'api_crawler.py'
TABLE_NAME = 'weather_forecast'

def run_update_script(script_name, message):
    """
    åŸ·è¡Œä¸€å€‹ Python è…³æœ¬ä¾†æ›´æ–°è³‡æ–™ã€‚
    - é¡¯ç¤ºåŸ·è¡Œä¸­çš„æç¤ºã€‚
    - æˆåŠŸæ™‚ï¼Œåœ¨å¯æŠ˜ç–Šå€å¡Šä¸­é¡¯ç¤ºæ—¥èªŒã€‚
    - å¤±æ•—æ™‚ï¼Œåƒ…é¡¯ç¤ºéŒ¯èª¤æ—¥èªŒçš„æœ€å¾Œå¹¾è¡Œï¼Œé¿å…æ´—ç‰ˆã€‚
    """
    st.info(message)
    script_path = os.path.join(BASE_DIR, script_name)
    
    try:
        with st.spinner(f"æ­£åœ¨åŸ·è¡Œ '{script_name}'ï¼Œéç¨‹å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“..."):
            process = subprocess.run(
                [sys.executable, script_path],
                check=True,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='ignore'
            )
        
        st.success(f"'{script_name}' åŸ·è¡ŒæˆåŠŸã€‚")
        with st.expander("æŸ¥çœ‹åŸ·è¡Œæ—¥èªŒ"):
            st.code(process.stdout)

        if process.stderr:
            st.warning(f"'{script_name}' åŸ·è¡Œæ™‚ç”¢ç”Ÿäº†è­¦å‘Šè¨Šæ¯ã€‚")
            with st.expander("æŸ¥çœ‹è­¦å‘Šæ—¥èªŒ"):
                st.code(process.stderr)
        return True

    except subprocess.CalledProcessError as e:
        st.error(f"åŸ·è¡Œ '{script_name}' å¤±æ•—ã€‚")
        if e.stderr:
            st.warning("éŒ¯èª¤æ‘˜è¦ (åƒ…é¡¯ç¤ºæ—¥èªŒçš„æœ€å¾Œéƒ¨åˆ†):")
            error_lines = e.stderr.strip().split('\n')
            st.code('\n'.join(error_lines[-15:]))
        
        print(f"--- ERROR: '{script_name}' failed ---")
        print(f"Return Code: {e.returncode}")
        print(f"STDOUT:\n{e.stdout}")
        print(f"STDERR:\n{e.stderr}")
        print("--- End of Error Log ---")
        return False

    except FileNotFoundError:
        st.error(f"æ‰¾ä¸åˆ°è…³æœ¬: '{script_path}'ã€‚")
        return False

def get_weather_data() -> pd.DataFrame:
    """å¾ data.db è³‡æ–™åº«è®€å–ä¸¦è™•ç†å¤©æ°£è³‡æ–™ã€‚"""
    if not os.path.exists(DB_FILE):
        return pd.DataFrame()
        
    try:
        conn = sqlite3.connect(DB_FILE)
        query = f"SELECT location_name, start_time, avg_temp, pop FROM {TABLE_NAME}"
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        df['start_time'] = pd.to_datetime(df['start_time'])
        df['avg_temp'] = pd.to_numeric(df['avg_temp'], errors='coerce')
        df['pop'] = pd.to_numeric(df['pop'], errors='coerce')
        
        return df.dropna()
    except Exception as e:
        st.error(f"è®€å–æˆ–è™•ç†è³‡æ–™åº« '{DB_FILE}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

def plot_weather_chart(df, y_col, title, y_label):
    """æ ¹æ“šæŒ‡å®šçš„è³‡æ–™è¡Œç¹ªè£½å¤©æ°£è¶¨å‹¢åœ–ã€‚"""
    st.header(title)
    fig, ax = plt.subplots(figsize=(12, 6))
    
    locations = df['location_name'].unique()
    
    try:
        colors = plt.cm.get_cmap('tab10', len(locations))
    except:
        colors = plt.cm.get_cmap('viridis', len(locations))

    for i, loc in enumerate(locations):
        loc_df = df[df['location_name'] == loc].sort_values(by='start_time')
        ax.plot(loc_df['start_time'], loc_df[y_col], marker='o', linestyle='-', label=loc, color=colors(i))

    ax.set_title(title, fontsize=16)
    ax.set_xlabel('æ™‚é–“')
    ax.set_ylabel(y_label)
    ax.legend(title='åœ°å€', bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(True, which='both', linestyle='--', linewidth=0.5)
    plt.xticks(rotation=45, ha='right')
    fig.tight_layout(rect=[0, 0, 0.85, 1])
    st.pyplot(fig)

@st.cache_data
def scrape_movies() -> pd.DataFrame:
    """
    çˆ¬å–é›»å½±è³‡è¨Šï¼Œé æ•¸å¾ 1 åˆ° 10
    æå–ï¼šé›»å½±åç¨±ã€è©•åˆ†ã€é¡å‹ã€é›»å½±åœ–ç‰‡ URL
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    movies = []
    base_url = "https://ssr1.scrape.center/page/{}"
    progress_placeholder = st.empty()
    
    for page in range(1, 11):
        try:
            url = base_url.format(page)
            progress_placeholder.info(f"æ­£åœ¨çˆ¬å–ç¬¬ {page}/10 é ...")
            
            response = requests.get(url, headers=headers, timeout=10, verify=False)
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            movie_items = soup.find_all('div', class_='item')
            
            for item in movie_items:
                try:
                    # é›»å½±åç¨±
                    name_elem = item.find('h2')
                    name = name_elem.text.strip() if name_elem else 'N/A'
                    
                    # è©•åˆ†ï¼ˆå¾ p class="score" æå–ï¼‰
                    score_elem = item.find('p', class_='score')
                    score = score_elem.text.strip() if score_elem else 'N/A'
                    
                    # é¡å‹ï¼ˆå¾ categories div ä¸­çš„ button å…§å®¹æå–ï¼‰
                    categories_buttons = item.find('div', class_='categories')
                    categories_list = []
                    if categories_buttons:
                        for btn in categories_buttons.find_all('button', class_='category'):
                            span = btn.find('span')
                            if span:
                                categories_list.append(span.text.strip())
                    categories = 'ã€'.join(categories_list) if categories_list else 'N/A'
                    
                    # é›»å½±åœ–ç‰‡ URLï¼ˆå¾ img æ¨™ç±¤çš„ src æå–ï¼‰
                    img_elem = item.find('img', class_='cover')
                    image_url = img_elem.get('src', 'N/A') if img_elem else 'N/A'
                    
                    movie_data = {
                        'é›»å½±åç¨±': name,
                        'è©•åˆ†': score,
                        'é¡å‹': categories,
                        'é›»å½±åœ–ç‰‡URL': image_url
                    }
                    
                    movies.append(movie_data)
                    
                except Exception as e:
                    continue
            
            time.sleep(1)
            
        except requests.exceptions.RequestException as e:
            progress_placeholder.warning(f"ç¬¬ {page} é çˆ¬å–å¤±æ•—: {e}")
            continue
    
    progress_placeholder.empty()
    return pd.DataFrame(movies)

def part1_weather():
    """Part 1 - å¤©æ°£é å ±"""
    st.title("ğŸ‡¹ğŸ‡¼ å°ç£å¤©æ°£é å ±å„€è¡¨æ¿")

    try:
        matplotlib.rcParams['font.family'] = 'Microsoft JhengHei'
        plt.rcParams['axes.unicode_minus'] = False
    except Exception:
        st.warning("ç„¡æ³•è¨­å®šä¸­æ–‡å­—é«” 'Microsoft JhengHei'ï¼Œåœ–è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤ºã€‚")

    if not os.path.exists(DB_FILE):
        st.warning(f"è³‡æ–™åº«æª”æ¡ˆ '{os.path.basename(DB_FILE)}' ä¸å­˜åœ¨ï¼Œå°‡è‡ªå‹•åŸ·è¡Œé¦–æ¬¡è³‡æ–™æ›´æ–°ã€‚")
        if run_update_script(CRAWLER_SCRIPT, f"æ­£åœ¨åŸ·è¡Œ '{CRAWLER_SCRIPT}' ä»¥å»ºç«‹è³‡æ–™åº«..."):
            st.success("è³‡æ–™åº«å·²æˆåŠŸå»ºç«‹ï¼é é¢å°‡é‡æ–°è¼‰å…¥ã€‚")
            st.rerun()
        else:
            st.error("åˆå§‹åŒ–è³‡æ–™åº«å¤±æ•—ï¼Œæ‡‰ç”¨ç¨‹å¼ç„¡æ³•å•Ÿå‹•ã€‚è«‹æŸ¥çœ‹çµ‚ç«¯æ©Ÿæ—¥èªŒä»¥ç²å–è©³ç´°è³‡è¨Šã€‚")
            return

    if st.button("ğŸ”„ æ›´æ–°å¤©æ°£è³‡æ–™"):
        if run_update_script(CRAWLER_SCRIPT, f"æ­£åœ¨å¾ API ç²å–æœ€æ–°è³‡æ–™..."):
            st.success("è³‡æ–™æ›´æ–°æˆåŠŸï¼")
            st.rerun()
        else:
            st.error("è³‡æ–™æ›´æ–°å¤±æ•—ã€‚")
    
    st.markdown("---")

    df = get_weather_data()

    if df.empty:
        st.info("ç›®å‰æ²’æœ‰å¯é¡¯ç¤ºçš„è³‡æ–™ï¼Œè«‹å…ˆæ›´æ–°è³‡æ–™ã€‚")
        return

    st.header("ğŸ“‹ å¤©æ°£é å ±è³‡æ–™è¡¨")
    df_display = df.copy()
    df_display['start_time'] = df_display['start_time'].dt.strftime('%m-%d %H:00')
    df_display.rename(columns={
        'location_name': 'åœ°é»',
        'start_time': 'æ™‚é–“',
        'avg_temp': 'å¹³å‡æº«åº¦',
        'pop': 'é™é›¨æ©Ÿç‡'
    }, inplace=True)
    
    st.dataframe(df_display[[
        'åœ°é»', 
        'æ™‚é–“', 
        'å¹³å‡æº«åº¦', 
        'é™é›¨æ©Ÿç‡'
    ]], use_container_width=True)

    st.markdown("---")

    col1, col2 = st.columns(2)
    with col1:
        plot_weather_chart(df, 'avg_temp', 'ğŸ“ˆ å„åœ°å€å¹³å‡æº«åº¦è¶¨å‹¢', 'æº«åº¦ (Â°C)')
    with col2:
        plot_weather_chart(df, 'pop', 'ğŸ’§ å„åœ°å€é™é›¨æ©Ÿç‡è¶¨å‹¢', 'é™é›¨æ©Ÿç‡ (%)')

def part2_movies():
    """Part 2 - é›»å½±çˆ¬èŸ²"""
    st.title("ğŸ¬ é›»å½±è³‡è¨Šåº«")
    st.markdown("çˆ¬å–è‡ª https://ssr1.scrape.center (ç¬¬ 1-10 é )")
    
    if st.button("ğŸ”„ é‡æ–°çˆ¬å–é›»å½±è³‡è¨Š", key="refresh_movies"):
        st.cache_data.clear()
        st.rerun()
    
    with st.spinner("æ­£åœ¨çˆ¬å–é›»å½±è³‡è¨Šï¼Œè«‹è€å¿ƒç­‰å€™..."):
        movies_df = scrape_movies()
    
    if not movies_df.empty:
        st.success(f"âœ… æˆåŠŸçˆ¬å– {len(movies_df)} éƒ¨é›»å½±ï¼")
        
        # ä¿å­˜ç‚º CSV
        csv_file = os.path.join(BASE_DIR, 'movie.csv')
        movies_df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        st.info(f"ğŸ“ æ•¸æ“šå·²è‡ªå‹•ä¿å­˜åˆ° `movie.csv`")
        
        st.markdown("---")
        st.header("ğŸ“Š é›»å½±è³‡è¨Šè¡¨")
        st.dataframe(movies_df, use_container_width=True)
        
        # æä¾› CSV ä¸‹è¼‰æŒ‰éˆ•
        csv_data = movies_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ç‚º CSV",
            data=csv_data,
            file_name="movie.csv",
            mime="text/csv"
        )
        
    else:
        st.error("ç„¡æ³•çˆ¬å–é›»å½±è³‡è¨Šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–ç¨å¾Œé‡è©¦ã€‚")

def main():
    """Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»å‡½å¼ã€‚"""
    st.set_page_config(page_title="å¤©æ°£é å ±èˆ‡é›»å½±è³‡è¨Š", layout="wide")

    st.sidebar.markdown("# ğŸ“‘ å°èˆªèœå–®")
    page = st.sidebar.radio(
        "é¸æ“‡é é¢",
        ["Part 1 - å¤©æ°£é å ±", "Part 2 - é›»å½±è³‡è¨Š"]
    )

    if page == "Part 1 - å¤©æ°£é å ±":
        part1_weather()
    elif page == "Part 2 - é›»å½±è³‡è¨Š":
        part2_movies()

if __name__ == "__main__":
    main()
